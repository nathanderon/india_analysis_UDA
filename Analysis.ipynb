{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 4,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "C:\\Users\\shrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
=======
      "C:\\Users\\deron\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Create single parliament_qs dataframe with all question data\n",
    "li = []\n",
    "\n",
    "for file in glob.glob('./Parliament_Qs/rajyasabha_questions_and_answers_*.csv'):\n",
    "    data = pd.read_csv(file)\n",
    "    li.append(data)\n",
    "    \n",
    "parliament_qs = pd.concat(li, axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code borrowed and adapted from George Chen, Carnegie Mellon University#\n",
    "#Define function to remove punctuation and whitespace, and lowercase all text\n",
    "def makeWordList(str_object):\n",
    "    \n",
    "    corpus_text = str(str_object)\n",
    "    \n",
    "    for c in string.punctuation:\n",
    "        corpus_text = corpus_text.replace(c, \"\")  # -- (1)\n",
    "    \n",
    "    text = re.sub(r'\\S*\\d\\S*','',corpus_text) # -- (2)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)         # -- (3)\n",
    "    \n",
    "    text = text.lower().split()           # -- (4)         \n",
    "    \n",
    "    li = []\n",
    "    for token in text:\n",
    "        li.append(token)\n",
    "\n",
    "    return \" \".join(li)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 42,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the questions\n",
    "processed_questions = []\n",
    "\n",
    "for str_object in list(parliament_qs[\"question_description\"]):\n",
    "    processed_questions.append(makeWordList(str_object))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 5,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process responses\n",
    "processed_answers = []\n",
    "\n",
    "for str_object in list(parliament_qs[\"answer\"]):\n",
    "    processed_answers.append(makeWordList(str_object))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 44,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use TfidfVectorizer to transform parliamentary questions\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=200, stop_words=\"english\", max_df=0.8)\n",
    "questions_fit = vectorizer.fit(processed_questions)\n",
    "X_questions = vectorizer.fit_transform(processed_questions).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='online', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=25, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!Time-consuming!#\n",
    "#Create topics using LDA\n",
    "num_topics = 10\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, learning_method='online', random_state=0)\n",
    "lda.fit(X_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the top 10 words per topic and their probabilities within the topic...\n",
      "\n",
      "[Topic 0]\n",
      "farmers : 0.03432249245161212\n",
      "yearb : 0.026567099768405548\n",
      "protect : 0.02627266876651353\n",
      "laid : 0.0209304713520839\n",
      "gap : 0.020743799326411416\n",
      "infrastructure : 0.01737843400376475\n",
      "framed : 0.016343367933292125\n",
      "proportion : 0.013992823441451217\n",
      "uttar : 0.012607052373335247\n",
      "hilly : 0.01126669775507691\n",
      "\n",
      "[Topic 1]\n",
      "schools : 0.02730456857790779\n",
      "prevention : 0.018332404680661035\n",
      "gap : 0.018234400143671847\n",
      "proposing : 0.01766699535761114\n",
      "infrastructure : 0.017467158235118\n",
      "office : 0.016923884403026834\n",
      "illegal : 0.016369272690784583\n",
      "proportion : 0.01394114323481971\n",
      "directed : 0.01377824782264445\n",
      "connectivity : 0.013186161367719605\n",
      "\n",
      "[Topic 2]\n",
      "infrastructure : 0.01978056271094503\n",
      "gap : 0.01919393376359035\n",
      "proportion : 0.016634871279066724\n",
      "provide : 0.016434012543051806\n",
      "laid : 0.013432106122968723\n",
      "crore : 0.012858883159405006\n",
      "directed : 0.012544519645980695\n",
      "norms : 0.012485378378116887\n",
      "partnership : 0.011463848052269784\n",
      "framework : 0.011135263857810475\n",
      "\n",
      "[Topic 3]\n",
      "news : 0.031324436821422545\n",
      "relief : 0.03081568269586868\n",
      "install : 0.0287984929566751\n",
      "grant : 0.028772654996151798\n",
      "resource : 0.026028607427898115\n",
      "punjab : 0.025070299667450398\n",
      "left : 0.021075370303605335\n",
      "limit : 0.019533647355146826\n",
      "processing : 0.019267212386819197\n",
      "quantity : 0.01889585155517809\n",
      "\n",
      "[Topic 4]\n",
      "regardc : 0.04294485074135219\n",
      "april : 0.024344906275656192\n",
      "gap : 0.02145579143176302\n",
      "infrastructure : 0.019363108473882975\n",
      "yearwise : 0.018433602035202876\n",
      "study : 0.01750409205777485\n",
      "internet : 0.017393996023343693\n",
      "proportion : 0.016056791229076207\n",
      "partnership : 0.0156068857440183\n",
      "slow : 0.015484869738026166\n",
      "\n",
      "[Topic 5]\n",
      "industrial : 0.05208919265297191\n",
      "groups : 0.041446964992169044\n",
      "roads : 0.037133007765479856\n",
      "envisaged : 0.03314240914821209\n",
      "orders : 0.03080630904555257\n",
      "contemplating : 0.030023803359501212\n",
      "farc : 0.029376256414467616\n",
      "zone : 0.029099758149449064\n",
      "radio : 0.028300519516646274\n",
      "brought : 0.027632067759820772\n",
      "\n",
      "[Topic 6]\n",
      "value : 0.02888583422461465\n",
      "mission : 0.021801882755330924\n",
      "infrastructure : 0.016870706941568128\n",
      "vegetables : 0.016203408882590434\n",
      "attention : 0.015515845011700252\n",
      "completely : 0.015417997969159748\n",
      "gap : 0.014643131015273987\n",
      "product : 0.014428327032212196\n",
      "bureau : 0.014217608471414827\n",
      "research : 0.013961954191041823\n",
      "\n",
      "[Topic 7]\n",
      "bureau : 0.020483892125107938\n",
      "infrastructure : 0.019634759475081108\n",
      "gram : 0.01805603564245378\n",
      "gap : 0.01719621152940104\n",
      "yearsc : 0.016615752235201675\n",
      "tribunal : 0.015320412638658895\n",
      "extension : 0.014181875440849166\n",
      "concerns : 0.014002570597767917\n",
      "approval : 0.013782685549955985\n",
      "agencies : 0.013145996797272028\n",
      "\n",
      "[Topic 8]\n",
      "concern : 0.020118985972161815\n",
      "uttarakhand : 0.01878453792079377\n",
      "crore : 0.018052486112234922\n",
      "challenges : 0.015790220670844613\n",
      "toilets : 0.015465590604344217\n",
      "loss : 0.015032691613988432\n",
      "crisis : 0.014658887455546823\n",
      "yearc : 0.01444626256450211\n",
      "infrastructure : 0.012738492758231378\n",
      "animals : 0.012711869977221645\n",
      "\n",
      "[Topic 9]\n",
      "nuclear : 0.02142458934328642\n",
      "compensation : 0.017473763019752373\n",
      "distribution : 0.016292152981684294\n",
      "sector : 0.014960171960909544\n",
      "filed : 0.0145946896068985\n",
      "ongc : 0.014569247587867982\n",
      "officials : 0.014362496554538426\n",
      "infrastructure : 0.013794943119292476\n",
      "laying : 0.013536687784568794\n",
      "december : 0.013429901022393246\n",
      "\n",
      "[Topic 10]\n",
      "activities : 0.05458135045768346\n",
      "toll : 0.04778240723583348\n",
      "spending : 0.03010899921766146\n",
      "combat : 0.028811221091395098\n",
      "november : 0.026648139952160553\n",
      "countryc : 0.02566446104757333\n",
      "reported : 0.023652978959836483\n",
      "ground : 0.02224742465354723\n",
      "decisions : 0.02201484750800077\n",
      "census : 0.02139707133745869\n",
      "\n",
      "[Topic 11]\n",
      "green : 0.04706103315855137\n",
      "notification : 0.03748367159545661\n",
      "obtained : 0.034366872466388414\n",
      "buildings : 0.0339691342712555\n",
      "odisha : 0.03147963511616169\n",
      "run : 0.028302767228505513\n",
      "ppp : 0.026390632928573646\n",
      "model : 0.0257837477146213\n",
      "consultation : 0.02574657316150099\n",
      "lives : 0.024761042212480776\n",
      "\n",
      "[Topic 12]\n",
      "partnership : 0.022698632132281037\n",
      "committed : 0.022366559378511192\n",
      "infrastructure : 0.022251349621169134\n",
      "gap : 0.02151122955102551\n",
      "laying : 0.020181955027429647\n",
      "permanent : 0.018566433120293532\n",
      "proportion : 0.015089496709806633\n",
      "specific : 0.014122631540563516\n",
      "integrated : 0.013398712701849013\n",
      "members : 0.013246669630599268\n",
      "\n",
      "[Topic 13]\n",
      "regular : 0.17135451464541415\n",
      "sites : 0.046500537862447365\n",
      "centres : 0.021796686143633025\n",
      "prevent : 0.021716333065989114\n",
      "farm : 0.02083199541857879\n",
      "category : 0.020744969480449432\n",
      "conservation : 0.01780867223335746\n",
      "timeline : 0.015850535160764834\n",
      "foreign : 0.014086848298911311\n",
      "meeting : 0.013422073592708101\n",
      "\n",
      "[Topic 14]\n",
      "success : 0.019898526471024764\n",
      "gap : 0.0172466405067744\n",
      "infrastructure : 0.01589289803178484\n",
      "approval : 0.01292709763214522\n",
      "nuclear : 0.012830976200077995\n",
      "allocations : 0.012062074507785134\n",
      "entered : 0.011584993565919306\n",
      "proportion : 0.011298997151579096\n",
      "respective : 0.011216157556034468\n",
      "yearsd : 0.01119346962219432\n",
      "\n",
      "[Topic 15]\n",
      "constructed : 0.06659396300546458\n",
      "holding : 0.034188330206328485\n",
      "clean : 0.027396709336153933\n",
      "kept : 0.02133318982496396\n",
      "launch : 0.018867190950464505\n",
      "benefits : 0.01879712432859493\n",
      "disputes : 0.01557176004951543\n",
      "cil : 0.015476744362017625\n",
      "produced : 0.01376175477195998\n",
      "infrastructure : 0.01370268267838042\n",
      "\n",
      "[Topic 16]\n",
      "threat : 0.03174408052272921\n",
      "organisation : 0.022085974359093048\n",
      "infrastructure : 0.01893095685353393\n",
      "gap : 0.01663536090666783\n",
      "andb : 0.015116588875838312\n",
      "slum : 0.015008251050608594\n",
      "entered : 0.013963106196847642\n",
      "suffering : 0.01379750057812522\n",
      "agencies : 0.013093199064702644\n",
      "tackle : 0.012271537758857321\n",
      "\n",
      "[Topic 17]\n",
      "rising : 0.031814994920034846\n",
      "thereofe : 0.026905330371439887\n",
      "trend : 0.022497369404980996\n",
      "dated : 0.022245743735344107\n",
      "chhattisgarh : 0.020623441797951742\n",
      "pattern : 0.017494521769582223\n",
      "passing : 0.016692185534981467\n",
      "crore : 0.015670840013975597\n",
      "reducing : 0.015274437359767709\n",
      "unstarred : 0.014852150012222945\n",
      "\n",
      "[Topic 18]\n",
      "procedure : 0.02895974500775163\n",
      "appointment : 0.025955997025707157\n",
      "sadak : 0.0251118827683884\n",
      "resulting : 0.020882279361447\n",
      "committed : 0.020263794045149566\n",
      "boost : 0.01998479074072778\n",
      "gap : 0.018744447480407007\n",
      "wind : 0.017484323922806848\n",
      "teaching : 0.01710816952634849\n",
      "laying : 0.016704551144624796\n",
      "\n",
      "[Topic 19]\n",
      "aircraft : 0.027563029015029866\n",
      "approval : 0.02278440154082828\n",
      "submitted : 0.019447852191383716\n",
      "shortage : 0.01766271212489564\n",
      "railways : 0.01572306307827185\n",
      "standard : 0.014149824770182643\n",
      "fixed : 0.013925515308271642\n",
      "route : 0.013672412292064234\n",
      "passenger : 0.013536931742027403\n",
      "department : 0.013303382361478685\n",
      "\n",
      "[Topic 20]\n",
      "report : 0.03688821777008524\n",
      "northeastern : 0.03465087679231372\n",
      "neighbouring : 0.027823785944729677\n",
      "illegally : 0.025670622252085506\n",
      "paramilitary : 0.023643163702218816\n",
      "conduct : 0.01800548935494357\n",
      "culture : 0.015084003816547255\n",
      "sea : 0.01412211710362178\n",
      "gap : 0.012766123380446652\n",
      "east : 0.012045237069606415\n",
      "\n",
      "[Topic 21]\n",
      "standard : 0.09813487753779387\n",
      "accidents : 0.08262505231974551\n",
      "granted : 0.07848878189985202\n",
      "forests : 0.06092916377050465\n",
      "interests : 0.04177727871960697\n",
      "execution : 0.030413100652675065\n",
      "priority : 0.02817151865292035\n",
      "provided : 0.0248358353050955\n",
      "transparency : 0.024210204250724683\n",
      "efficiency : 0.02104606978620811\n",
      "\n",
      "[Topic 22]\n",
      "delhib : 0.03920111140783965\n",
      "thereford : 0.031541850681611916\n",
      "ministers : 0.030893058828881544\n",
      "countryd : 0.0302780936892643\n",
      "followed : 0.028758783803077854\n",
      "unani : 0.025470297491964514\n",
      "speedy : 0.02397526814103012\n",
      "wise : 0.020186014307202627\n",
      "rajasthan : 0.020032049804682924\n",
      "vacant : 0.019187259515751853\n",
      "\n",
      "[Topic 23]\n",
      "infrastructure : 0.020827530716370973\n",
      "gap : 0.01709145041977403\n",
      "hilly : 0.014268756014861935\n",
      "proportion : 0.014024561629870922\n",
      "make : 0.013775319257764767\n",
      "statea : 0.011775469038864991\n",
      "mw : 0.011702151446136767\n",
      "achieving : 0.011410477137366397\n",
      "technology : 0.011397626109352866\n",
      "slum : 0.01136286188412567\n",
      "\n",
      "[Topic 24]\n",
      "approval : 0.04182140297544441\n",
      "clearances : 0.023542619863020676\n",
      "amend : 0.02216466303389794\n",
      "ganga : 0.021430515440916526\n",
      "gap : 0.019514732480791566\n",
      "functional : 0.01882827973676488\n",
      "blocks : 0.017942591406928745\n",
      "infrastructure : 0.01547876059032573\n",
      "detected : 0.015422575200932919\n",
      "proportion : 0.014793374711378204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display top 10 words from each topic\n",
    "words = list(questions_fit.vocabulary_)\n",
    "topic_word_distributions = np.array([row / row.sum() for row in lda.components_])\n",
    "num_top_words = 10\n",
    "\n",
    "print('Displaying the top 10 words per topic and their probabilities within the topic...')\n",
    "print()\n",
    "\n",
    "for topic_idx in range(num_topics):\n",
    "    print('[Topic ', topic_idx, ']', sep='')\n",
    "    sort_indices = np.argsort(-topic_word_distributions[topic_idx])\n",
    "    for rank in range(num_top_words):\n",
    "        word_idx = sort_indices[rank]\n",
    "        print(words[word_idx], ':', topic_word_distributions[topic_idx, word_idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": 6,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use TfidfVectorizer to transform parliamentary answers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=200, stop_words=\"english\", max_df=0.8)\n",
    "answers_fit = vectorizer.fit(processed_answers)\n",
    "X_answers = vectorizer.fit_transform(processed_answers).toarray()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 7,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='online', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
<<<<<<< HEAD
       "                          mean_change_tol=0.001, n_components=25, n_jobs=None,\n",
=======
       "                          mean_change_tol=0.001, n_components=1, n_jobs=None,\n",
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
       "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 33,
=======
     "execution_count": 7,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!Time-consuming!#\n",
    "#Create topics using LDA\n",
    "num_topics = 1\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_answers = LatentDirichletAllocation(n_components=num_topics, learning_method='online', random_state=0)\n",
    "lda_answers.fit(X_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the top 10 words per topic and their probabilities within the topic...\n",
      "\n",
      "[Topic 0]\n",
      "load : 0.005080913309441476\n",
      "putting : 0.004528057922306874\n",
      "combat : 0.00337049316574227\n",
      "tenders : 0.0032544913669188755\n",
      "pointed : 0.0030894443827827107\n",
      "input : 0.0030116696759138707\n",
      "right : 0.002530522656239383\n",
      "manohar : 0.002518004393962288\n",
      "matters : 0.0024367377372698845\n",
      "cashless : 0.0024249497925367225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display top 10 words from each topic\n",
    "words = list(answers_fit.vocabulary_)\n",
    "topic_word_distributions = np.array([row / row.sum() for row in lda_answers.components_])\n",
    "num_top_words = 10\n",
    "\n",
    "print('Displaying the top 10 words per topic and their probabilities within the topic...')\n",
    "print()\n",
    "\n",
    "for topic_idx in range(num_topics):\n",
    "    print('[Topic ', topic_idx, ']', sep='')\n",
    "    sort_indices = np.argsort(-topic_word_distributions[topic_idx])\n",
    "    for rank in range(num_top_words):\n",
    "        word_idx = sort_indices[rank]\n",
    "        print(words[word_idx], ':', topic_word_distributions[topic_idx, word_idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_answers.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Topic 0]\n",
      "religious : 9.899338423836855e-05\n",
      "muslim : 0.00013176865515226625\n",
      "temple : 0.00014931508323882134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print religious word occurances\n",
    "words = list(answers_fit.vocabulary_)\n",
    "topic_word_distributions = np.array([row / row.sum() for row in lda_answers.components_])\n",
    "res = []\n",
    "for religious_word in religious_vocab:\n",
    "    if religious_word in words:\n",
    "        res.append(words.index(religious_word))\n",
    "#res = [words.index(religious_word) for religious_word in religious_vocab]\n",
    "\n",
    "#print('Displaying the top 10 words per topic and their probabilities within the topic...')\n",
    "#print()\n",
    "\n",
    "for topic_idx in range(num_topics):\n",
    "    print('[Topic ', topic_idx, ']', sep='')\n",
    "    sort_indices = np.argsort(-topic_word_distributions[topic_idx])\n",
    "    for i in res:\n",
    "        print(words[i], ':', topic_word_distributions[topic_idx, i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headline Analysis"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
=======
   "execution_count": 26,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "\n",
    "for file in glob.glob('./india_headlines_data_pre/*.csv'):\n",
    "    data = pd.read_csv(file)\n",
    "    li.append(data)\n",
    "    \n",
    "headlines = pd.concat(li, axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
=======
   "execution_count": 16,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process headlines, delete headlines object, sample 10% of processed headlines\n",
    "import random\n",
    "processed_headlines = []\n",
    "random.seed(42)\n",
    "headlines = random.sample(list(headlines[\"headline_text\"]), round(len(headlines)/10))\n",
    "                          \n",
    "for str_object in headlines:\n",
    "    processed_headlines.append(makeWordList(str_object))\n",
    "del headlines"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
=======
   "execution_count": 17,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use TfidfVectorizer to transform headlines\n",
    "##Memory intensive##\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=200, stop_words=\"english\", max_df=0.8)\n",
    "headlines_fit = vectorizer.fit(processed_headlines)\n",
    "X_headlines = vectorizer.fit_transform(processed_headlines).toarray()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
=======
   "execution_count": 18,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='online', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=1, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 37,
=======
     "execution_count": 18,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_topics = 1\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_headlines = LatentDirichletAllocation(n_components=num_topics, learning_method='online', random_state=0)\n",
    "lda_headlines.fit(X_headlines)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
=======
   "execution_count": 19,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the top 10 words per topic and their probabilities within the topic...\n",
      "\n",
      "[Topic 0]\n",
<<<<<<< HEAD
      "case : 0.04245535049327792\n",
      "lawyers : 0.04194710684974531\n",
      "committee : 0.03039749351075891\n",
      "shows : 0.027897974196539853\n",
      "nadu : 0.02738394202467435\n",
      "temple : 0.026017193045103987\n",
      "results : 0.024992521976250823\n",
      "kin : 0.023503842733620856\n",
      "officials : 0.022527731789709543\n",
      "tata : 0.019661655197470495\n",
      "\n",
      "[Topic 1]\n",
      "girls : 0.05660259507016469\n",
      "chinese : 0.04885269668925603\n",
      "pradesh : 0.031937048703189336\n",
      "global : 0.029220226784184514\n",
      "week : 0.027248386444122353\n",
      "chief : 0.02596484415498291\n",
      "strike : 0.022630580763288267\n",
      "rs : 0.02185553593980609\n",
      "come : 0.02183397836081487\n",
      "policy : 0.02076531021701119\n",
      "\n",
      "[Topic 2]\n",
      "cpm : 0.059628168824674116\n",
      "double : 0.036820912738072135\n",
      "station : 0.03057534870123872\n",
      "ties : 0.028173939532232885\n",
      "uk : 0.02623499148455631\n",
      "gas : 0.02530141652155499\n",
      "cbi : 0.025066281466011284\n",
      "train : 0.02487405456563125\n",
      "hits : 0.02343105634464284\n",
      "despite : 0.022767854808258093\n",
      "\n",
      "[Topic 3]\n",
      "mlas : 0.051012376846652205\n",
      "assembly : 0.04906526513200058\n",
      "sc : 0.04453030688611366\n",
      "andhra : 0.035507941604801876\n",
      "stars : 0.035373947307129824\n",
      "theft : 0.031956559747553036\n",
      "jail : 0.029431839507097938\n",
      "political : 0.02761393432569712\n",
      "singh : 0.020908164690732332\n",
      "online : 0.020604835487207766\n",
      "\n",
      "[Topic 4]\n",
      "role : 0.10007618110446173\n",
      "sent : 0.04125986845566057\n",
      "record : 0.02951792343579489\n",
      "launches : 0.027272960137447733\n",
      "pranab : 0.02512805779647436\n",
      "host : 0.024344104977026174\n",
      "man : 0.02056314173132294\n",
      "polls : 0.0203429604500669\n",
      "protest : 0.01981670552732231\n",
      "free : 0.019586959004486374\n",
      "\n",
      "[Topic 5]\n",
      "dies : 0.05313863826328704\n",
      "join : 0.036843016752337934\n",
      "opens : 0.03299070400755181\n",
      "right : 0.032859578822407406\n",
      "today : 0.03258564724975546\n",
      "probe : 0.027400948487435208\n",
      "funds : 0.02568339777401773\n",
      "mishap : 0.02508719114773861\n",
      "lives : 0.02421022685867524\n",
      "easy : 0.020919080024120948\n",
      "\n",
      "[Topic 6]\n",
      "board : 0.051828325999675455\n",
      "blasts : 0.04284197532081692\n",
      "officer : 0.04096564325884854\n",
      "flu : 0.039805332446857085\n",
      "begins : 0.03153292899568806\n",
      "maharashtra : 0.025183865942991414\n",
      "months : 0.02512380785865792\n",
      "got : 0.02008636607578242\n",
      "killing : 0.01862709758501208\n",
      "power : 0.018369611899958754\n",
      "\n",
      "[Topic 7]\n",
      "booked : 0.07593451720016775\n",
      "sp : 0.052527790862928546\n",
      "indians : 0.038436835477234164\n",
      "faces : 0.032751138171827905\n",
      "farmers : 0.03245309867493198\n",
      "self : 0.02553055821581236\n",
      "loan : 0.025302432548275872\n",
      "teacher : 0.02444043756754145\n",
      "mumbai : 0.02393853785921474\n",
      "fall : 0.023686553982285644\n",
      "\n",
      "[Topic 8]\n",
      "arms : 0.11393513476147925\n",
      "gets : 0.07114224790200098\n",
      "marriage : 0.05500808065818779\n",
      "seat : 0.03159858153660788\n",
      "cabinet : 0.028120445283486794\n",
      "returns : 0.02330094934680767\n",
      "key : 0.020766086868280194\n",
      "firms : 0.02004965414522749\n",
      "low : 0.019671907480843628\n",
      "force : 0.01960254245253238\n",
      "\n",
      "[Topic 9]\n",
      "leader : 0.08316819132687685\n",
      "sales : 0.05717358843444216\n",
      "issue : 0.03978094044035687\n",
      "class : 0.03879181246817557\n",
      "keeps : 0.027667423576987725\n",
      "start : 0.026690566186752696\n",
      "nagpur : 0.02200013884737561\n",
      "park : 0.020421283870820345\n",
      "just : 0.02025772458848764\n",
      "parking : 0.01842754733686521\n",
=======
      "jharkhand : 0.0065510867561133865\n",
      "buildings : 0.006426498052493539\n",
      "bollywood : 0.005626572128150678\n",
      "scheme : 0.005334077461047131\n",
      "nepal : 0.005098348272174378\n",
      "mission : 0.00466473557659236\n",
      "courts : 0.004617878634466528\n",
      "turn : 0.004236775877263603\n",
      "diesel : 0.004174504895286561\n",
      "release : 0.0041646727805514806\n",
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
      "\n"
     ]
    }
   ],
   "source": [
    "words = list(headlines_fit.vocabulary_)\n",
    "topic_word_distributions = np.array([row / row.sum() for row in lda_headlines.components_])\n",
    "num_top_words = 10\n",
    "\n",
    "print('Displaying the top 10 words per topic and their probabilities within the topic...')\n",
    "print()\n",
    "\n",
    "for topic_idx in range(num_topics):\n",
    "    print('[Topic ', topic_idx, ']', sep='')\n",
    "    sort_indices = np.argsort(-topic_word_distributions[topic_idx])\n",
    "    for rank in range(num_top_words):\n",
    "        word_idx = sort_indices[rank]\n",
    "        print(words[word_idx], ':', topic_word_distributions[topic_idx, word_idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 22,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [],
   "source": [
    "religious_vocab = ['religion', 'religious', 'hindu', 'hinduism',\n",
    "                  'islam', 'muslim', 'christianity', 'christian', 'sikh',\n",
    "                  'sikhism', 'temple', 'mosque', 'church', 'divine', 'god', 'gods',\n",
    "                  'prayer', 'prayers', 'priest', 'clergy', 'imam', 'monk', 'dharma',\n",
<<<<<<< HEAD
    "                  'vedas', 'worship', 'worshippers', 'worshipers' 'worshipper', 'worshiper', 'ayodhya', \n",
    "                   'babri', 'hindutva','lynching','ethnic', 'purity','nationalism', 'nationalist',\n",
    "                   'RSS', 'Sangh'\n",
=======
    "                  'vedas', 'worship', 'worshippers', 'worshipers' 'worshipper', 'worshiper',\n",
    "                   'purity', 'nationalism', 'cleansing', 'ethnic'\n",
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 23,
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Topic 0]\n",
<<<<<<< HEAD
      "temple : 0.026017193045103987\n",
      "\n",
      "[Topic 1]\n",
      "temple : 4.612405221720102e-06\n",
      "\n",
      "[Topic 2]\n",
      "temple : 4.471391925941976e-06\n",
      "\n",
      "[Topic 3]\n",
      "temple : 4.421048464554521e-06\n",
      "\n",
      "[Topic 4]\n",
      "temple : 4.890719999289956e-06\n",
      "\n",
      "[Topic 5]\n",
      "temple : 4.3786520085485e-06\n",
      "\n",
      "[Topic 6]\n",
      "temple : 4.720136870275732e-06\n",
      "\n",
      "[Topic 7]\n",
      "temple : 4.5560359835007115e-06\n",
      "\n",
      "[Topic 8]\n",
      "temple : 4.792114959804868e-06\n",
      "\n",
      "[Topic 9]\n",
      "temple : 4.028074617747339e-06\n",
=======
      "hindu : 0.0005553395375425462\n",
      "muslim : 0.0004621399519305284\n",
      "sikh : 0.0009201208716710891\n",
      "temple : 0.00035964578241502596\n",
>>>>>>> 8c1abac4efa8a3c82c0c422d3a94d1624f13db3f
      "\n"
     ]
    }
   ],
   "source": [
    "#Print religious word occurances\n",
    "words = list(headlines_fit.vocabulary_)\n",
    "topic_word_distributions = np.array([row / row.sum() for row in lda_headlines.components_])\n",
    "\n",
    "res = []\n",
    "for religious_word in religious_vocab:\n",
    "    if religious_word in words:\n",
    "        res.append(words.index(religious_word))\n",
    "#res = [words.index(religious_word) for religious_word in religious_vocab]\n",
    "\n",
    "#print('Displaying the top 10 words per topic and their probabilities within the topic...')\n",
    "#print()\n",
    "\n",
    "for topic_idx in range(num_topics):\n",
    "    print('[Topic ', topic_idx, ']', sep='')\n",
    "    sort_indices = np.argsort(-topic_word_distributions[topic_idx])\n",
    "    for i in res:\n",
    "        print(words[i], ':', topic_word_distributions[topic_idx, i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
