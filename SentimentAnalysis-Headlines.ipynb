{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'UDA_pytorch_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b1c254c32d35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mUDA_pytorch_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUDA_LSTMforSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUDA_pytorch_classifier_fit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mUDA_plot_train_val_accuracy_vs_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUDA_pytorch_classifier_predict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mUDA_compute_accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'UDA_pytorch_utils'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from UDA_pytorch_utils import UDA_LSTMforSequential, UDA_pytorch_classifier_fit, \\\n",
    "    UDA_plot_train_val_accuracy_vs_epoch, UDA_pytorch_classifier_predict, \\\n",
    "    UDA_compute_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11ff36a10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('india-news-headlines-1.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    headlines1 = []\n",
    "    for row in readCSV:\n",
    "        headline = row[2]\n",
    "        headlines1.append(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11ff36a10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchnlp.datasets import imdb_dataset\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 84.1MB [00:25, 3.26MB/s]                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = imdb_dataset(train=True)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_train_size = int(len(train_dataset) * 0.8)\n",
    "val_size = len(train_dataset) - proper_train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_train_dataset, val_dataset = torch.utils.data.random_split(train_dataset,\n",
    "                                                                  [proper_train_size,\n",
    "                                                                   val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\"Heartland\" is a wonderful depiction of what it was really like to live on the frontier. The hard work and individual strength that were needed to survive the hardships of the climate and the lack of medical care are blended with the camaraderie and the interdependence of the settlers. The drama was especially meaningful because the story is based on the diaries of real people whose descendants still live there. It was also nice to see the west inhabited by real people. No one was glamorous or looked as if they had just spent a session with the makeup or costume department. Conchatta Ferrell is just wonderful. She is an example of the strong, persevering people who came to Wyoming in the early 20th century and let no hardship stand in their way of a new life in a new land.',\n",
       " 'sentiment': 'pos'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proper_train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.encoders.text import SpacyEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SpacyEncoder([data['text'] for data in proper_train_dataset])\n",
    "proper_train_encoded = [encoder.encode(data['text']) for data in proper_train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_train_labels = torch.tensor([int(data['sentiment'] == 'pos') for data in proper_train_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_encoded = [encoder.encode(data['text']) for data in val_dataset]\n",
    "val_labels = torch.tensor([int(data['sentiment'] == 'pos') for data in val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_train_dataset_encoded = list(zip(proper_train_encoded, proper_train_labels))\n",
    "val_dataset_encoded = list(zip(val_encoded, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "glove.6B.zip: 862MB [06:49, 2.11MB/s]                               \n",
      "100%|██████████| 400000/400000 [00:33<00:00, 12050.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchnlp.word_to_vector import GloVe\n",
    "pretrained_embedding = GloVe(name='6B', dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = torch.Tensor(encoder.vocab_size, pretrained_embedding.dim)\n",
    "for i, token in enumerate(encoder.vocab):\n",
    "    embedding_weights[i] = pretrained_embedding[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_lstm_model = nn.Sequential(nn.Embedding.from_pretrained(embedding_weights),\n",
    "                                  UDA_LSTMforSequential(100, 64),\n",
    "                                  nn.Linear(64, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [==================================================] 20000/20000\n",
      "  Train accuracy: 0.7698\n",
      "  Validation accuracy: 0.7694\n",
      "Epoch 2 [==================================================] 20000/20000\n",
      "  Train accuracy: 0.8174\n",
      "  Validation accuracy: 0.8056\n",
      "Epoch 3 [==================================================] 20000/20000\n",
      "  Train accuracy: 0.8657\n",
      "  Validation accuracy: 0.8486\n",
      "Epoch 4 [==================================================] 20000/20000\n",
      "  Train accuracy: 0.8815\n",
      "  Validation accuracy: 0.8552\n",
      "Epoch 5 [==================================================] 20000/20000\n",
      "  Train accuracy: 0.8979\n",
      "  Validation accuracy: 0.8560\n",
      "Epoch 6 [==================================================] 20000/20000\n",
      "  Train accuracy: 0.8307\n",
      "  Validation accuracy: 0.7992\n",
      "Epoch 7 [==================================================] 20000/20000\n",
      "  Train accuracy: 0.9082\n",
      "  Validation accuracy: 0.8572\n",
      "Epoch 8 [==================================================] 20000/20000\n",
      "  Train accuracy: 0.9112\n",
      "  Validation accuracy: 0.8530\n",
      "Epoch 9 [==================================================] 20000/20000\n",
      "  Train accuracy: 0.9221\n",
      "  Validation accuracy: 0.8566\n",
      "Epoch 10 [==================================================] 20000/20000\n",
      "  Train accuracy: 0.9237\n",
      "  Validation accuracy: 0.8580\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # during optimization, how many times we look at training data\n",
    "batch_size = 64  # during optimization, how many training data to use at each step\n",
    "learning_rate = 0.01  # during optimization, how much we nudge our solution at each step\n",
    "\n",
    "train_accuracies, val_accuracies = \\\n",
    "    UDA_pytorch_classifier_fit(simple_lstm_model,\n",
    "                               torch.optim.Adam(simple_lstm_model.parameters(),\n",
    "                                                lr=learning_rate),\n",
    "                               nn.CrossEntropyLoss(),  # includes softmax\n",
    "                               proper_train_dataset_encoded, val_dataset_encoded,\n",
    "                               num_epochs, batch_size,\n",
    "                               sequence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'win over cena satisfying but defeating undertaker bigger roman reigns'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive is 1, Negative is 0\n",
    "UDA_pytorch_classifier_predict(simple_lstm_model,\n",
    "                               [encoder.encode(headlines1[1])],\n",
    "                               sequence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He is the king of 'five star' industry\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines1[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive is 1, Negative is 0\n",
    "UDA_pytorch_classifier_predict(simple_lstm_model,\n",
    "                               [encoder.encode(headlines1[99])],\n",
    "                               sequence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Dudhwa tiger died of starvation; not poisoning'\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines1[135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive is 1, Negative is 0\n",
    "UDA_pytorch_classifier_predict(simple_lstm_model,\n",
    "                               [encoder.encode(headlines1[135])],\n",
    "                               sequence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
